{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Kaggle competition Submission</center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMMI Bootcamp Kaggle competition\n",
    "\n",
    "- This was a project assign students to develop a predictive model for wine prices with given features. \n",
    "- Predict the price of a bottle of wine based on a collection of over one hundred thousand reviews and other product features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import all necessary packages \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style \n",
    "style.use(\"ggplot\")\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is a fine rich balanced wine. It has ripe...</td>\n",
       "      <td>Vila Santa Reserva</td>\n",
       "      <td>88.870874</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PORTUGUESE RED</td>\n",
       "      <td>J. Portugal Ramos</td>\n",
       "      <td>32027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>France</td>\n",
       "      <td>A solid, chunky wine, with a structure that is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.041695</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Lalande de Pomerol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Tour Grand Colombier</td>\n",
       "      <td>71079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>France</td>\n",
       "      <td>This is powerful and concentrated, with the hi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.085021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Saint-Émilion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Figeac</td>\n",
       "      <td>32440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Rich, ripe and oaky, this Petite Sirah charms ...</td>\n",
       "      <td>Thompson Vineyard</td>\n",
       "      <td>89.869797</td>\n",
       "      <td>34.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Barbara County</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jaffurs 2010 Thompson Vineyard Petite Sirah (S...</td>\n",
       "      <td>PETITE SIRAH</td>\n",
       "      <td>Jaffurs</td>\n",
       "      <td>124405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  \\\n",
       "0  Portugal  This is a fine rich balanced wine. It has ripe...   \n",
       "1    France  A solid, chunky wine, with a structure that is...   \n",
       "2    France  This is powerful and concentrated, with the hi...   \n",
       "3        US  Rich, ripe and oaky, this Petite Sirah charms ...   \n",
       "\n",
       "          designation     points  price    province              region_1  \\\n",
       "0  Vila Santa Reserva  88.870874   20.0  Alentejano                   NaN   \n",
       "1                 NaN  88.041695   28.0    Bordeaux    Lalande de Pomerol   \n",
       "2                 NaN  94.085021  130.0    Bordeaux         Saint-Émilion   \n",
       "3   Thompson Vineyard  89.869797   34.0  California  Santa Barbara County   \n",
       "\n",
       "        region_2 taster_name taster_twitter_handle  \\\n",
       "0            NaN         NaN                   NaN   \n",
       "1            NaN         NaN                   NaN   \n",
       "2            NaN         NaN                   NaN   \n",
       "3  Central Coast         NaN                   NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  Jaffurs 2010 Thompson Vineyard Petite Sirah (S...   \n",
       "\n",
       "                    variety                        winery      id  \n",
       "0            PORTUGUESE RED             J. Portugal Ramos   32027  \n",
       "1  BORDEAUX-STYLE RED BLEND  Château Tour Grand Colombier   71079  \n",
       "2  BORDEAUX-STYLE RED BLEND                Château Figeac   32440  \n",
       "3              PETITE SIRAH                       Jaffurs  124405  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Import the data using pandas module read_csv\n",
    "### Reading the training and testing datasets.\n",
    "Train_data = pd.read_csv(\"train_competition.csv\")\n",
    "Test_data = pd.read_csv(\"test.csv\")\n",
    "Data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                      47\n",
       "description                   0\n",
       "designation               52266\n",
       "points                        0\n",
       "price                         0\n",
       "province                     47\n",
       "region_1                  28534\n",
       "region_2                  99606\n",
       "taster_name              109491\n",
       "taster_twitter_handle    112810\n",
       "title                     92811\n",
       "variety                       1\n",
       "winery                        0\n",
       "id                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the number of missing values in the train dataset each feature. \n",
    "Train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                        0\n",
       "country                     17\n",
       "description                  0\n",
       "designation              24824\n",
       "points                       0\n",
       "price                    83210\n",
       "province                    17\n",
       "region_1                 13883\n",
       "region_2                 47608\n",
       "taster_name              52240\n",
       "taster_twitter_handle    53841\n",
       "title                    44424\n",
       "variety                      0\n",
       "winery                       0\n",
       "id                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check the number of missing values in the test set \n",
    "Test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175000 entries, 0 to 174999\n",
      "Data columns (total 14 columns):\n",
      "country                  174953 non-null object\n",
      "description              175000 non-null object\n",
      "designation              122734 non-null object\n",
      "points                   175000 non-null float64\n",
      "price                    175000 non-null float64\n",
      "province                 174953 non-null object\n",
      "region_1                 146466 non-null object\n",
      "region_2                 75394 non-null object\n",
      "taster_name              65509 non-null object\n",
      "taster_twitter_handle    62190 non-null object\n",
      "title                    82189 non-null object\n",
      "variety                  174999 non-null object\n",
      "winery                   175000 non-null object\n",
      "id                       175000 non-null int64\n",
      "dtypes: float64(2), int64(1), object(11)\n",
      "memory usage: 18.7+ MB\n"
     ]
    }
   ],
   "source": [
    "### To check the feature characteristics of each column in the train dataset.\n",
    "Train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimensional checks of the dataframe \n",
    "def dimension_check(Data):\n",
    "    ##print out the shape of the data.\n",
    "    print(\"The shape of the dataset with row: \",Data.shape[0],\"\\n\") \n",
    "    print(\"The shape of the dataset with columns: \",Data.shape[1],\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset with row:  175000 \n",
      "\n",
      "The shape of the dataset with columns:  14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### The shape of the columns and rows in the dataset.\n",
    "dimension_check(Data=Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset with row:  83210 \n",
      "\n",
      "The shape of the dataset with columns:  15 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### The shape of the columns and rows in the dataset.\n",
    "dimension_check(Data=Test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of data\n",
    "\n",
    "- At this point of the analysis, we want to perform some preprocess techniques on the dataset. For instance: missing values. This is the cleaning stage of data modelling. We need to treat the missing values in each feature column of the dataframe for both training and test set. \n",
    "\n",
    "- We need to perform some missing values imputation or dropping of missing value. \n",
    "\n",
    "- Both training and test dataset must be treated differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a copy of the data \n",
    "Train_copy = Train_data.copy()\n",
    "Test_copy = Test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                      47\n",
       "description                   0\n",
       "designation               52266\n",
       "points                        0\n",
       "price                         0\n",
       "province                     47\n",
       "region_1                  28534\n",
       "region_2                  99606\n",
       "taster_name              109491\n",
       "taster_twitter_handle    112810\n",
       "title                     92811\n",
       "variety                       1\n",
       "winery                        0\n",
       "id                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### To treat the missing values for each dataset \n",
    "Train_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                       0\n",
       "description                   0\n",
       "designation               52257\n",
       "points                        0\n",
       "price                         0\n",
       "province                      0\n",
       "region_1                  28486\n",
       "region_2                  99558\n",
       "taster_name              109486\n",
       "taster_twitter_handle    112805\n",
       "title                     92807\n",
       "variety                       0\n",
       "winery                        0\n",
       "id                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Drop missing values with small number \n",
    "## Country, province, variety\n",
    "Train_copy = Train_copy.dropna(subset=[\"country\",\"province\",\"variety\"])\n",
    "Train_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Drop features which are not important in the dataframe \n",
    "##### Define a function to drop  \n",
    "def drop_features(Data,non_important):\n",
    "    Data = Data.drop(non_important,axis=\"columns\")\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'description', 'designation', 'points', 'price', 'province',\n",
       "       'region_1', 'region_2', 'variety', 'winery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_copy = drop_features(Data=Train_copy,non_important=['taster_name','taster_twitter_handle','id','title'])\n",
    "Train_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'description', 'designation', 'points', 'province',\n",
       "       'region_1', 'region_2', 'variety', 'winery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Drop all non-informative features\n",
    "Test_copy = drop_features(Data=Test_copy,non_important=['index','price','taster_name','taster_twitter_handle','id','title'])\n",
    "Test_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From the data information there was no information for those columns. So we had to replace with no location.\n",
    "def missing_town(Data,feature):\n",
    "    Data[feature] = Data[feature].fillna(\"No location\")\n",
    "    return Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_copy = missing_town(Data=Train_copy,feature=\"region_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_copy = missing_town(Data=Test_copy,feature=\"region_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_name</th>\n",
       "      <th>Number_of_uniqueness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>designation</td>\n",
       "      <td>37912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>province</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>region_1</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>region_2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>variety</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>winery</td>\n",
       "      <td>16957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column_name  Number_of_uniqueness\n",
       "0  designation                 37912\n",
       "1     province                   468\n",
       "2     region_1                  1278\n",
       "3     region_2                    19\n",
       "4      variety                   702\n",
       "5       winery                 16957"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check for the uniqueness in each feature. \n",
    "Features = [\"designation\",\"province\",\"region_1\",\"region_2\",\"variety\",\"winery\"]\n",
    "def Uniqueness(Data,Feature):\n",
    "    ### \n",
    "    Unique_character = []\n",
    "    Feature = []\n",
    "    for i in Features:\n",
    "        counts = Data[i].nunique()\n",
    "        Unique_character.append(counts)\n",
    "        Feature.append(i)\n",
    "    Feat = pd.DataFrame({\"Column_name\": Feature,\"Number_of_uniqueness\":Unique_character})\n",
    "    return Feat\n",
    "#### Check for train set\n",
    "Uniqueness(Data=Train_copy,Feature=Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_name</th>\n",
       "      <th>Number_of_uniqueness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>designation</td>\n",
       "      <td>25487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>province</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>region_1</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>region_2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>variety</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>winery</td>\n",
       "      <td>13962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column_name  Number_of_uniqueness\n",
       "0  designation                 25487\n",
       "1     province                   423\n",
       "2     region_1                  1145\n",
       "3     region_2                    19\n",
       "4      variety                   622\n",
       "5       winery                 13962"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check for the uniqueness in each feature. \n",
    "## Check for test set\n",
    "Uniqueness(Data=Test_copy,Feature=Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country            0\n",
       "description        0\n",
       "designation    52257\n",
       "points             0\n",
       "price              0\n",
       "province           0\n",
       "region_1       28486\n",
       "region_2           0\n",
       "variety            0\n",
       "winery             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country           17\n",
       "description        0\n",
       "designation    24824\n",
       "points             0\n",
       "province          17\n",
       "region_1       13883\n",
       "region_2           0\n",
       "variety            0\n",
       "winery             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filling the missing values with of the categorical features with mode \n",
    "def filling_missing(Data):\n",
    "    for m in Data.columns:\n",
    "        if Data[m].isnull().sum() > 0: \n",
    "            Data[m] = Data[m].fillna(Data[m].mode()[0])\n",
    "    return Data \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        0\n",
       "description    0\n",
       "designation    0\n",
       "points         0\n",
       "price          0\n",
       "province       0\n",
       "region_1       0\n",
       "region_2       0\n",
       "variety        0\n",
       "winery         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_copy = filling_missing(Data=Train_copy)\n",
    "Train_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        0\n",
       "description    0\n",
       "designation    0\n",
       "points         0\n",
       "province       0\n",
       "region_1       0\n",
       "region_2       0\n",
       "variety        0\n",
       "winery         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_copy = filling_missing(Data=Test_copy)\n",
    "Test_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering \n",
    "\n",
    "- At this stage of the analysis, we want to perform some feature engineering before building the model. Both data have column feature with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the tensorflow framework and other text processing modules \n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_train = Train_copy[\"price\"]\n",
    "X_labels_train = Train_copy.drop(\"price\",axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'description', 'designation', 'points', 'province',\n",
       "       'region_1', 'region_2', 'variety', 'winery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check for columns names of the input features\n",
    "X_labels_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'description', 'designation', 'points', 'province',\n",
       "       'region_1', 'region_2', 'variety', 'winery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check for columns names of the test set. \n",
    "Test_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((174952, 9), (83210, 9))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check for the shape of the model. \n",
    "X_labels_train.shape, Test_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the nltk package by using the word_tokenize module.\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is a fine rich balanced wine. It has ripe...</td>\n",
       "      <td>Vila Santa Reserva</td>\n",
       "      <td>88.870874</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>No location</td>\n",
       "      <td>PORTUGUESE RED</td>\n",
       "      <td>J. Portugal Ramos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>France</td>\n",
       "      <td>A solid, chunky wine, with a structure that is...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>88.041695</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Lalande de Pomerol</td>\n",
       "      <td>No location</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Tour Grand Colombier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>France</td>\n",
       "      <td>This is powerful and concentrated, with the hi...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>94.085021</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Saint-Émilion</td>\n",
       "      <td>No location</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Figeac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Rich, ripe and oaky, this Petite Sirah charms ...</td>\n",
       "      <td>Thompson Vineyard</td>\n",
       "      <td>89.869797</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Barbara County</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>PETITE SIRAH</td>\n",
       "      <td>Jaffurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>This wine is a unique in the state blend and f...</td>\n",
       "      <td>McKinley Springs Vineyard</td>\n",
       "      <td>89.017651</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Horse Heaven Hills</td>\n",
       "      <td>Columbia Valley</td>\n",
       "      <td>ROSé</td>\n",
       "      <td>Syncline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  \\\n",
       "0  Portugal  This is a fine rich balanced wine. It has ripe...   \n",
       "1    France  A solid, chunky wine, with a structure that is...   \n",
       "2    France  This is powerful and concentrated, with the hi...   \n",
       "3        US  Rich, ripe and oaky, this Petite Sirah charms ...   \n",
       "4        US  This wine is a unique in the state blend and f...   \n",
       "\n",
       "                 designation     points    province              region_1  \\\n",
       "0         Vila Santa Reserva  88.870874  Alentejano           Napa Valley   \n",
       "1                    Reserve  88.041695    Bordeaux    Lalande de Pomerol   \n",
       "2                    Reserve  94.085021    Bordeaux         Saint-Émilion   \n",
       "3          Thompson Vineyard  89.869797  California  Santa Barbara County   \n",
       "4  McKinley Springs Vineyard  89.017651  Washington    Horse Heaven Hills   \n",
       "\n",
       "          region_2                   variety                        winery  \n",
       "0      No location            PORTUGUESE RED             J. Portugal Ramos  \n",
       "1      No location  BORDEAUX-STYLE RED BLEND  Château Tour Grand Colombier  \n",
       "2      No location  BORDEAUX-STYLE RED BLEND                Château Figeac  \n",
       "3    Central Coast              PETITE SIRAH                       Jaffurs  \n",
       "4  Columbia Valley                      ROSé                      Syncline  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_labels_train[X_labels_train[\"designation\"] == \"...\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Napa': 5010,\n",
       "         'No location': 47608,\n",
       "         'Central Coast': 7788,\n",
       "         'Sonoma': 6505,\n",
       "         'Columbia Valley': 5478,\n",
       "         'California Other': 1927,\n",
       "         'Willamette Valley': 2098,\n",
       "         'Finger Lakes': 1050,\n",
       "         'Central Valley': 700,\n",
       "         'Sierra Foothills': 961,\n",
       "         'Long Island': 468,\n",
       "         'Mendocino/Lake Counties': 729,\n",
       "         'Napa-Sonoma': 898,\n",
       "         'Washington Other': 384,\n",
       "         'North Coast': 395,\n",
       "         'New York Other': 99,\n",
       "         'Oregon Other': 431,\n",
       "         'Southern Oregon': 529,\n",
       "         'South Coast': 152})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Test_copy[\"region_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        0\n",
       "description    0\n",
       "designation    0\n",
       "points         0\n",
       "province       0\n",
       "region_1       0\n",
       "region_2       0\n",
       "variety        0\n",
       "winery         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_labels_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        0\n",
       "description    0\n",
       "designation    0\n",
       "points         0\n",
       "province       0\n",
       "region_1       0\n",
       "region_2       0\n",
       "variety        0\n",
       "winery         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_process(Train,Test):\n",
    "    ### In this part of the code, we perform some tokenization here. \n",
    "    points = Train[[\"points\"]]\n",
    "    points1 = Test[[\"points\"]]\n",
    "    Train = Train[['country', 'description', 'designation', 'province','region_1', 'region_2', 'variety', 'winery']]\n",
    "    Test = Test[['country', 'description', 'designation', 'province','region_1', 'region_2', 'variety', 'winery']]\n",
    "    vocabulary_size = 25000\n",
    "    _word = lambda words: len(word_tokenize(words))\n",
    "    Train_dict = {}\n",
    "    Test_dict = {}\n",
    "    for columns in Train.columns:\n",
    "        Longest_sentence = max(Train[columns],key=_word)\n",
    "        Longest_length_sentence = len(word_tokenize(Longest_sentence))\n",
    "        Train_col = [one_hot(token,vocabulary_size) for token in Train[columns]]\n",
    "        Test_col = [one_hot(token,vocabulary_size) for token in Test[columns]]\n",
    "        Train_dict[columns] = pad_sequences(Train_col,Longest_length_sentence,padding=\"post\")\n",
    "        Test_dict[columns] = pad_sequences(Test_col,Longest_length_sentence,padding=\"post\")\n",
    "    ### Concatenate the features engineered.\n",
    "    X_train = np.concatenate((Train_dict[\"country\"],Train_dict[\"description\"],Train_dict[\"designation\"],Train_dict[\"province\"],Train_dict[\"region_1\"],Train_dict[\"region_2\"],Train_dict[\"variety\"],Train_dict[\"winery\"],points.to_numpy()),axis=1)\n",
    "    X_test = np.concatenate((Test_dict[\"country\"],Test_dict[\"description\"],Test_dict[\"designation\"],Test_dict[\"province\"],Test_dict[\"region_1\"],Test_dict[\"region_2\"],Test_dict[\"variety\"],Test_dict[\"winery\"],points1.to_numpy()),axis=1)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = tokenize_process(Train=X_labels_train,Test=Test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174952, 213)\n",
      "(83210, 213)\n"
     ]
    }
   ],
   "source": [
    "### Check for dimension for both training and testing \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install the nltk packages\n",
    "#import nltk\n",
    "#nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the packages in tensorflow framework.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store the correct model.\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define our networks using the Sequential in models modules\n",
    "embed_dimension = 25\n",
    "Model = Sequential([\n",
    "    layers.Embedding(input_dim = 25000,output_dim=embed_dimension,input_length=X_train.shape[1]),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(13,activation=\"relu\"),\n",
    "    layers.Dense(18,activation=\"relu\"),\n",
    "    layers.Dense(1,activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set our optimizer using Adam with their given parameters \n",
    "optimizer = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "Model.compile(optimizer=optimizer,loss=\"mean_squared_error\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 213, 25)           625000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5325)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                69238     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                252       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 694,509\n",
      "Trainable params: 694,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122466 samples, validate on 52486 samples\n",
      "Epoch 1/20\n",
      "122430/122466 [============================>.] - ETA: 0s - loss: 44.3336 - accuracy: 0.0000e+00\n",
      "Epoch 00001: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 69s 566us/sample - loss: 44.3263 - accuracy: 0.0000e+00 - val_loss: 541.7136 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "122390/122466 [============================>.] - ETA: 0s - loss: 47.2112 - accuracy: 0.0000e+00\n",
      "Epoch 00002: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 71s 581us/sample - loss: 47.2524 - accuracy: 0.0000e+00 - val_loss: 551.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "122410/122466 [============================>.] - ETA: 0s - loss: 42.3497 - accuracy: 0.0000e+00\n",
      "Epoch 00003: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 72s 590us/sample - loss: 42.3379 - accuracy: 0.0000e+00 - val_loss: 534.9016 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "122460/122466 [============================>.] - ETA: 0s - loss: 39.9895 - accuracy: 0.0000e+00\n",
      "Epoch 00004: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 78s 633us/sample - loss: 39.9888 - accuracy: 0.0000e+00 - val_loss: 550.7515 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "122450/122466 [============================>.] - ETA: 0s - loss: 37.6480 - accuracy: 0.0000e+00\n",
      "Epoch 00005: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 77s 630us/sample - loss: 37.6471 - accuracy: 0.0000e+00 - val_loss: 547.1455 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "122440/122466 [============================>.] - ETA: 0s - loss: 34.5257 - accuracy: 0.0000e+00\n",
      "Epoch 00006: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 77s 628us/sample - loss: 34.5225 - accuracy: 0.0000e+00 - val_loss: 546.2284 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "122400/122466 [============================>.] - ETA: 0s - loss: 31.2902 - accuracy: 0.0000e+00\n",
      "Epoch 00007: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 73s 596us/sample - loss: 31.2804 - accuracy: 0.0000e+00 - val_loss: 558.5455 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "122460/122466 [============================>.] - ETA: 0s - loss: 31.0283 - accuracy: 0.0000e+00\n",
      "Epoch 00008: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 76s 617us/sample - loss: 31.0274 - accuracy: 0.0000e+00 - val_loss: 545.7447 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "122410/122466 [============================>.] - ETA: 0s - loss: 28.0580 - accuracy: 0.0000e+00\n",
      "Epoch 00009: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 70s 575us/sample - loss: 28.0823 - accuracy: 0.0000e+00 - val_loss: 543.8070 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "122420/122466 [============================>.] - ETA: 0s - loss: 29.8868 - accuracy: 0.0000e+00\n",
      "Epoch 00010: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 69s 567us/sample - loss: 29.8826 - accuracy: 0.0000e+00 - val_loss: 544.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "122380/122466 [============================>.] - ETA: 0s - loss: 26.2988 - accuracy: 0.0000e+00\n",
      "Epoch 00011: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 72s 589us/sample - loss: 26.2953 - accuracy: 0.0000e+00 - val_loss: 532.5587 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "122420/122466 [============================>.] - ETA: 0s - loss: 27.2675 - accuracy: 0.0000e+00\n",
      "Epoch 00012: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 74s 605us/sample - loss: 27.2626 - accuracy: 0.0000e+00 - val_loss: 543.1817 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "122410/122466 [============================>.] - ETA: 0s - loss: 25.8090 - accuracy: 0.0000e+00\n",
      "Epoch 00013: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 75s 611us/sample - loss: 25.8013 - accuracy: 0.0000e+00 - val_loss: 536.7142 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "122460/122466 [============================>.] - ETA: 0s - loss: 22.3279 - accuracy: 0.0000e+00\n",
      "Epoch 00014: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 76s 617us/sample - loss: 22.3272 - accuracy: 0.0000e+00 - val_loss: 538.6757 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "122430/122466 [============================>.] - ETA: 0s - loss: 25.1954 - accuracy: 0.0000e+00\n",
      "Epoch 00015: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 75s 615us/sample - loss: 25.1905 - accuracy: 0.0000e+00 - val_loss: 535.8881 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "122420/122466 [============================>.] - ETA: 0s - loss: 20.1690 - accuracy: 0.0000e+00\n",
      "Epoch 00016: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 77s 629us/sample - loss: 20.1657 - accuracy: 0.0000e+00 - val_loss: 538.9867 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "122410/122466 [============================>.] - ETA: 0s - loss: 24.8598 - accuracy: 0.0000e+00\n",
      "Epoch 00017: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 71s 577us/sample - loss: 24.8705 - accuracy: 0.0000e+00 - val_loss: 538.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "122460/122466 [============================>.] - ETA: 0s - loss: 20.0157 - accuracy: 0.0000e+00\n",
      "Epoch 00018: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 74s 605us/sample - loss: 20.0151 - accuracy: 0.0000e+00 - val_loss: 537.6557 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "122380/122466 [============================>.] - ETA: 0s - loss: 22.4299 - accuracy: 0.0000e+00\n",
      "Epoch 00019: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 73s 597us/sample - loss: 22.4207 - accuracy: 0.0000e+00 - val_loss: 536.5829 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "122450/122466 [============================>.] - ETA: 0s - loss: 17.2099 - accuracy: 0.0000e+00\n",
      "Epoch 00020: val_accuracy did not improve from 0.00000\n",
      "122466/122466 [==============================] - 73s 594us/sample - loss: 17.2084 - accuracy: 0.0000e+00 - val_loss: 545.8426 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdfb58f2e10>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Fit the train data to our model by training it for 50 epoch with batch size of 20\n",
    "Model.fit(X_train, y_label_train, epochs=20, batch_size = 10, validation_split=0.3, callbacks=callbacks_list, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission1 = Test_data[[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission1[\"price\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-b851a17d091a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Submission' is not defined"
     ]
    }
   ],
   "source": [
    "Submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.261703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.950363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60.686573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23.301657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13.390927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       price\n",
       "0   0  100.261703\n",
       "1   1   39.950363\n",
       "2   2   60.686573\n",
       "3   3   23.301657\n",
       "4   4   13.390927"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission1.to_csv(\"Submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
